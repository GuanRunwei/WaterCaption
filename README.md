# WaterCaption: A Fine-Grained Image Captioning Dataset for Inland Waterways

## ðŸ“˜ Overview

**WaterCaption** is a large-scale, fine-grained image captioning dataset specifically designed for **inland waterway scenes** based on **Unmanned Surface Vehicles (USVs)**. WaterCaption, the first captioning dataset specifically designed for waterway environments. WaterCaption focuses on fine-grained, multi-region long-text descriptions, providing a new research direction for visual geo-understanding and spatial scene cognition. Exactly, it includes 20.2k image-text pair data with 1.8 million vocabulary size.


---

## ðŸ“‚ Dataset Structure

```
WaterCaption/
â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ captions/
â”‚ â”œâ”€â”€ images/
â”œâ”€â”€ test/
â””â”€â”€ val/
```


Each image is annotated with multiple captions describing scene elements such as ships, buoys, bridges, and water conditions.

---

## ðŸ“Š Statistics

- **Images**: 20.2k
- **Average captions per image**: 1
- **Scene types**: Rivers, ports, bridges, canals, â€¦â€¦
- **Annotation format**: mllm-type (e.g. LLaVA, InternVL, â€¦â€¦)

---

## ðŸš€ Baseline Models

We release several benchmark models:

### ðŸ§  InternVL + Baseline


### âš¡ MobileVLM + Baseline

---

## ðŸ”§ Usage

### 1. Clone the Repository

```bash
git clone https://github.com/yourname/WaterCaption.git
cd WaterCaption
```

## ðŸ“˜ Citation
```
@article{guan2025yu,
  title={Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding},
  author={Guan, Runwei and Ouyang, Ningwei and Xu, Tianhao and Liang, Shaofeng and Dai, Wei and Sun, Yafeng and Gao, Shang and Lai, Songning and Yao, Shanliang and Hu, Xuming and others},
  journal={arXiv preprint arXiv:2506.19288},
  year={2025}
}
```


